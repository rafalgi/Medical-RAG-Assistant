{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8c0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_ollama import ChatOllama \n",
    "from IPython.display import Image, display\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langgraph.graph import StateGraph, START, END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14582942-f7b3-4743-a695-ff8f1d91b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a69bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"predicted_class\": \"Mosquito Bites\",\\n  \"prediction_confidences\": {\\n    \"Mosquito Bites\": 0.5,\\n    \"Bedbug Bites\": 0.2,\\n    \"Tick Bites\": 0.05,\\n    \"Flea Bites\": 0.1,\\n    \"Chigger Bites\": 0.05,\\n    \"Spider Bites\": 0.05,\\n    \"Ant Bites\": 0.03,\\n    \"Bee Stings\": 0.02\\n  }\\n}\\n```'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "\n",
    "model_gemini = genai.GenerativeModel('models/gemini-2.0-flash')\n",
    "\n",
    "image = r\"E:\\Deep_Learning\\Skin diseases\\data_bite\\train\\fleas\\fleas_3.jpg\"\n",
    "image = Image.open(image)\n",
    "\n",
    "prompt = '''You are a medical image classification assistant.\n",
    "Given an image of a skin condition, classify it into one of the following categories:\n",
    "\n",
    "1. Mosquito Bites\n",
    "2. Bedbug Bites\n",
    "3. Tick Bites\n",
    "4. Flea Bites\n",
    "5. Chigger Bites\n",
    "6. Spider Bites\n",
    "7. Ant Bites\n",
    "8. Bee Stings\n",
    "\n",
    "Please analyze the image and respond ONLY in the following dictionary format:\n",
    "\n",
    "{\n",
    "  \"predicted_class\": \"<class name from above>\",\n",
    "  \"prediction_confidences\": {\n",
    "    \"Mosquito Bites\": <probability between 0 and 1>,\n",
    "    \"Bedbug Bites\": <probability between 0 and 1>,\n",
    "    \"Tick Bites\": <probability between 0 and 1>,\n",
    "    \"Flea Bites\": <probability between 0 and 1>,\n",
    "    \"Chigger Bites\": <probability between 0 and 1>,\n",
    "    \"Spider Bites\": <probability between 0 and 1>,\n",
    "    \"Ant Bites\": <probability between 0 and 1>,\n",
    "    \"Bee Stings\": <probability between 0 and 1>\n",
    "  }\n",
    "}\n",
    "\n",
    "Where:\n",
    "- \"predicted_class\" is the class with the highest probability.\n",
    "- \"prediction_confidences\" is a dictionary with the probability for each class (all values between 0 and 1, and should sum to 1).\n",
    "\n",
    "If you are unsure, distribute the probabilities accordingly.\n",
    "'''\n",
    "\n",
    "response = model_gemini.generate_content([prompt, image]  )\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ccc20-9b6f-49b1-bbdf-893cbe8d517f",
   "metadata": {},
   "source": [
    "# Architecture \n",
    "\n",
    "![Medical RAG](images/Medical_RAG_Application.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072de32",
   "metadata": {},
   "source": [
    "# Graph\n",
    "\n",
    "1. Add Image processing, as a Node with will return probability of belongig to a given class with and class ✔️\n",
    "2. RAG (retrieval)                                                                                          ✔️\n",
    "4. LLM response                                                                                             ✔️\n",
    "5. Conversation Summarization                                                                               ✔️\n",
    "6. Smart query routing                                                                                      ✔️\n",
    "7. Build User Interface with streamlit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1181a80",
   "metadata": {},
   "source": [
    "# LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56947efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\")\n",
    "embedings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")\n",
    "#model = ChatOllama(model=\"deepseek-r1:7b\", temperature=0.1)\n",
    "model_for_query_route = ChatOllama(model = \"llama3.2:latest\")\n",
    "#embedings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856d941-ad41-4221-bb7f-06d9237e58c7",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11dd235c-2643-4d1f-b1b7-970cdaddd416",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "# Role\n",
    "You are a medical AI assistant focused on Question-Answering (QA) tasks within a Retrieval-Augmented Generation (RAG) system.\n",
    "Your primary goal is to provide precise answers based on the given context, image analysis, chat history, and conversation summary.\n",
    "\n",
    "# Instruction\n",
    "Provide a concise, logical answer by organizing the selected content into coherent paragraphs with a natural flow. \n",
    "Avoid merely listing information. Include key numerical values, technical terms, jargon, and names. \n",
    "DO NOT use any outside knowledge or information that is not in the given material.\n",
    "\n",
    "# Constraint\n",
    "- Review the provided context, image analysis, chat history, and conversation summary thoroughly and extract key details related to the question.\n",
    "- Craft a precise answer based on the relevant information.\n",
    "- Keep the answer concise but logical/natural/in-depth.\n",
    "- If the retrieved context does not contain relevant information or no context is available, respond with: 'I can't find the answer to that question in the context.'\n",
    "\n",
    "**Source** \n",
    "- Cite the source of the information as a file name with a page number or URL, omitting the source if it cannot be identified.\n",
    "- (list more if there are multiple sources)\n",
    "\n",
    "# Sources\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name  \n",
    "[2] Link or Document name\n",
    "\n",
    "- Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/  \n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "# Conversation Summary\n",
    "<summary>\n",
    "{summary}\n",
    "</summary>\n",
    "\n",
    "# Question\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "# Image Analysis\n",
    "<image_analysis>\n",
    "The image has been classified as: {predicted_class}\n",
    "Prediction confidence: {confidence:.2%}\n",
    "</image_analysis>\n",
    "\n",
    "# Context\n",
    "<retrieved context>\n",
    "{context}\n",
    "</retrieved context>\n",
    "\n",
    "# Answer\n",
    "'''\n",
    "\n",
    "template_for_no_image = '''\n",
    "# Role\n",
    "You are a medical AI assistant focused on Question-Answering (QA) tasks within a Retrieval-Augmented Generation (RAG) system.\n",
    "Your primary goal is to provide precise answers based on the given context, chat history, and conversation summary.\n",
    "\n",
    "# Instruction\n",
    "Provide a concise, logical answer by organizing the selected content into coherent paragraphs with a natural flow. \n",
    "Avoid merely listing information. Include key numerical values, technical terms, jargon, and names. \n",
    "DO NOT use any outside knowledge or information that is not in the given material.\n",
    "\n",
    "# Constraint\n",
    "- Review the provided context, chat history, and conversation summary thoroughly and extract key details related to the question.\n",
    "- Craft a precise answer based on the relevant information.\n",
    "- Keep the answer concise but logical/natural/in-depth.\n",
    "- If the retrieved context does not contain relevant information or no context is available, respond with: 'I can't find the answer to that question in the context.'\n",
    "\n",
    "**Source** \n",
    "- Cite the source of the information as a file name with a page number or URL, omitting the source if it cannot be identified.\n",
    "- (list more if there are multiple sources)\n",
    "\n",
    "# Sources\n",
    "- Include all sources used in your report\n",
    "- Provide full links to relevant websites or specific document paths\n",
    "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
    "- It will look like:\n",
    "\n",
    "### Sources\n",
    "[1] Link or Document name  \n",
    "[2] Link or Document name\n",
    "\n",
    "- Be sure to combine sources. For example this is not correct:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/  \n",
    "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "There should be no redundant sources. It should simply be:\n",
    "\n",
    "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
    "\n",
    "# Conversation Summary\n",
    "<summary>\n",
    "{summary}\n",
    "</summary>\n",
    "\n",
    "# Question\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "# Context\n",
    "<retrieved context>\n",
    "{context}\n",
    "</retrieved context>\n",
    "\n",
    "# Answer\n",
    "\n",
    "'''\n",
    "\n",
    "route_question_template = '''\n",
    "# Role\n",
    "You are an expert system that routes user health-related questions to either a vectorstore or a web search engine.\n",
    "\n",
    "# Vectorstore Contents\n",
    "The retrive contains documents related to:\n",
    "- Wounds and cuts: how to clean, treat, and care for them\n",
    "- Insect bites and stings: symptoms, treatments, and prevention\n",
    "- Skin injuries caused by physical trauma or bites\n",
    "\n",
    "Use the vectorstore if the user's question clearly falls into one of these categories.\n",
    "\n",
    "# Routing Rules\n",
    "- If the question concerns wound care, insect bites, stings, or minor skin injuries — use the **vectorstore**.\n",
    "- For all other medical topics (e.g. internal diseases, medication side effects, diagnostics, etc.) or unrelated queries — use **web search**.\n",
    "\n",
    "Always make a clear and accurate decision between the two options: `retrive` or `websearch`.\n",
    "'''\n",
    "\n",
    "grade_documents_template = \"\"\"\n",
    "You are an expert AI system for document evaluation.\n",
    "\n",
    "Your task is to assess whether the provided documents contain information that directly helps to answer the given question.\n",
    "\n",
    "Return ONLY:\n",
    "- True — if the documents are relevant to the question.\n",
    "- False — if the documents are not relevant to the question.\n",
    "\n",
    "Guidelines:\n",
    "- \"Relevant\" means the documents either directly answer or clearly help to answer the question.\n",
    "- If the documents are off-topic, missing key details, or only slightly related, they are considered NOT relevant.\n",
    "- Do not infer or guess beyond the given content. Only judge based on the text provided.\n",
    "\n",
    "Respond ONLY with True or False, without any explanation.\n",
    "\"\"\"\n",
    "\n",
    "check_hallucination_template = \"\"\"\n",
    "You are an expert fact-checker.\n",
    "\n",
    "Your task is to verify if the provided LLM-generated answer is fully grounded in the provided documents (facts).\n",
    "\n",
    "Return ONLY:\n",
    "- True — if the answer is directly supported by the documents.\n",
    "- False — if the answer contains information not found or contradicted by the documents.\n",
    "\n",
    "Guidelines:\n",
    "- Only accept answers that are clearly based on the provided facts.\n",
    "- If the answer includes invented, assumed, or unrelated information — mark as False.\n",
    "- Do not infer missing information or \"fill gaps\". Only check based on the given facts.\n",
    "\n",
    "Respond only with True or False, without any explanation.\"\"\"\n",
    "\n",
    "answer_question_template = \"\"\"\n",
    "You are a grader assessing whether an AI-generated answer successfully addresses the user's question.\n",
    "\n",
    "Return ONLY:\n",
    "- True — if the answer correctly and clearly responds to the user's question.\n",
    "- False — if the answer is irrelevant, incomplete, off-topic, or wrong.\n",
    "\n",
    "Guidelines:\n",
    "- An answer is acceptable if it is correct, clear, and meaningfully answers the question.\n",
    "- If the answer is too vague, partially correct, or off-topic — mark as False.\n",
    "- Focus only on the relation between the question and the provided answer.\n",
    "\n",
    "Respond only with True or False, without any additional comments.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b982c",
   "metadata": {},
   "source": [
    "# Create vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd50f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split website into 386 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "web_paths = ['https://medlineplus.gov/ency/article/000033.html',\n",
    "             'https://pmc.ncbi.nlm.nih.gov/articles/PMC10503338/',\n",
    "             'https://www.ncbi.nlm.nih.gov/books/NBK537235/',\n",
    "             'https://medicaljournalssweden.se/actadv/article/view/11592/19144',\n",
    "             'https://emedicine.medscape.com/article/769067-overview?form=fpf',\n",
    "             'https://www.mayoclinic.org/first-aid/first-aid-insect-bites/basics/art-20056593',\n",
    "             'https://www.medicalnewstoday.com/articles/174229#reactions',\n",
    "             'https://www.aafp.org/pubs/afp/issues/2022/0800/arthropod-bites-stings.html',\n",
    "             'https://wwwnc.cdc.gov/travel/page/avoid-bug-bites',\n",
    "             'https://www.webmd.com/first-aid/ss/slideshow-caring-for-wounds',\n",
    "             'https://www.mayoclinic.org/first-aid/first-aid-cuts/basics/art-20056711',\n",
    "             'https://www.betterhealth.vic.gov.au/health/conditionsandtreatments/wounds-how-to-care-for-them']\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=web_paths,\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                         chunk_overlap=400,\n",
    "                                         add_start_index=True)\n",
    "\n",
    "all_splits = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Split website into {len(all_splits)} sub-documents.\")\n",
    "\n",
    "\n",
    "\n",
    "vectorstores = FAISS.from_documents(documents=all_splits,\n",
    "                                    embedding=embedings)\n",
    "\n",
    "retriver = vectorstores.as_retriever(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de015862-8295-4efb-a165-40b5e3f1b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive(state):\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents based on image classification and user question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state, including 'image_metadata' and 'question'.\n",
    "\n",
    "    Returns:\n",
    "        dict: New state with a key 'retrived_docs' containing the retrieved documents.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---RETRIVE---\")\n",
    "    question = state.get(\"question\")\n",
    "\n",
    "    if state.get(\"image\") is not None:\n",
    "        prediction = state.get(\"image_metadata\", {})\n",
    "        cls = prediction.get(\"predicted_class\")\n",
    "        conf = prediction.get(\"prediction_confidences\")\n",
    "\n",
    "        probability = conf.get(cls , 0)\n",
    "    \n",
    "        query = f\"This question relates to a medical image classified as: {cls} with probability {probability}\"\n",
    "\n",
    "        print(f\"Retrieval query: {query}\")\n",
    "    \n",
    "        documents = retriver.invoke(query)\n",
    "\n",
    "    else: \n",
    "        print(f\"Retrieval query:{question}\")\n",
    "        documents = retriver.invoke(question)\n",
    "        \n",
    "    return {\n",
    "        \"retrived_docs\" : [documents]\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2240d",
   "metadata": {},
   "source": [
    "# Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09345190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model_path = r\"E:\\Deep_Learning\\Skin diseases\\best_model.h5\"\n",
    "model_cv = load_model(model_path)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 150\n",
    "channels = 3\n",
    "classes = ['Bite', 'Healthy Skin', 'Wound']\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image not loaded correctly from path: {image_path}\")\n",
    "        \n",
    "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    img = img.reshape(1, IMAGE_SIZE, IMAGE_SIZE, channels)\n",
    "    img = img / 255.0\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def analyze_image_node(state):\n",
    "    \"\"\"\n",
    "    Analyze the image and generate predictions for classification.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state containing the 'image' path.\n",
    "\n",
    "    Returns:\n",
    "        dict: New state with a key 'image_metadata' including predicted class and confidence scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---IMAGE ANALYSIS---\")\n",
    "    \n",
    "    image_path = state.get(\"image\")\n",
    "\n",
    "    if not image_path:\n",
    "        print(\"No image provided to input\")\n",
    "        return {}\n",
    "\n",
    "    # Preprocess + prediction\n",
    "    img = preprocess_image(image_path)\n",
    "    prediction = model_cv.predict(img)\n",
    "    \n",
    "    confidences = {cls: float(conf) for cls, conf in zip(classes, prediction[0])}\n",
    "    predicted_class = max(confidences, key=confidences.get)\n",
    "\n",
    "    return {\n",
    "        \"image_metadata\": {\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"prediction_confidences\": confidences\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881bbcdc",
   "metadata": {},
   "source": [
    "# Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37421acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def generate_response(state):\n",
    "    \"\"\"\n",
    "    Generate a final answer based on the retrieved documents, classification result, and user question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state containing 'image_metadata', 'retrived_docs', and 'question'.\n",
    "\n",
    "    Returns:\n",
    "        dict: New state with a key 'answer' containing the generated response.\n",
    "    \"\"\"\n",
    "    print(\"---GENERATION OF RESPONSE---\")\n",
    "\n",
    "    question = state.get(\"question\")\n",
    "    retrived_docs = state.get(\"retrived_docs\")\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    cls = None\n",
    "    conf = None\n",
    "\n",
    "    if state.get(\"image\"):\n",
    "        prediction = state.get(\"image_metadata\", {})\n",
    "        cls = prediction.get(\"predicted_class\")\n",
    "        conf = prediction.get(\"prediction_confidences\", {}).get(cls, 0)\n",
    "\n",
    "    prompt_template = template if state.get(\"image\") else template_for_no_image\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "    \n",
    "    model_response = model.invoke(\n",
    "        prompt.format(\n",
    "            question=question,\n",
    "            context=retrived_docs,\n",
    "            predicted_class=cls,\n",
    "            confidence=conf,\n",
    "            summary=summary or \"There is no chat history yet\"\n",
    "        )\n",
    "    )\n",
    "    token_count_usage = model_response.usage_metadata\n",
    "    token_count = state.get(\"token_count\", [])\n",
    "    if not isinstance(token_count, list):\n",
    "        token_count = []  \n",
    "\n",
    "    token_count.append(token_count_usage)\n",
    "    return {\n",
    "        \"answer\": [model_response],\n",
    "        \"token_usage\" : token_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a0c88e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: None\n",
      "content='I\\'m here to help you with a wide range of tasks! Here are some examples of things I can do:\\n\\n*   **Answer questions:** I can provide information on a vast array of topics, from science and history to current events and pop culture.\\n*   **Generate text:** I can write stories, poems, articles, scripts, and other creative content.\\n*   **Summarize information:** I can condense lengthy articles or documents into shorter, more manageable summaries.\\n*   **Translate languages:** I can translate text between multiple languages.\\n*   **Write different kinds of creative content:** I can generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc. I will try my best to fulfill all your requirements.\\n*   **Brainstorm ideas:** I can help you come up with ideas for projects, events, or solutions to problems.\\n*   **Provide definitions:** I can define words and concepts.\\n*   **Offer suggestions:** I can suggest books, movies, restaurants, and other things based on your preferences.\\n*   **Help with research:** I can find relevant information and resources for your research projects.\\n*   **Proofread and edit text:** I can help you improve the grammar, spelling, and clarity of your writing.\\n*   **Provide code snippets and explanations:** I can help with basic coding tasks and explain code concepts.\\n\\n**To help me assist you effectively, please be specific about what you need. For example, instead of saying \"Tell me about history,\" you could say \"Tell me about the history of the Roman Empire.\"**\\n\\nSo, what can I do for you today?' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--f7346e4b-773b-4039-95ec-86bf7118dedc-0'\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"Hi what i can do for you?\")\n",
    "tokens = response.usage_metadata\n",
    "print(f\"Token count: {tokens}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e506c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GENERATION OF RESPONSE---\n",
      "---TEST RESULTS---\n",
      "Generated answer: [AIMessage(content='To treat a simple cut, first clean the wound with mild soap and water. After cleaning, apply an antibiotic ointment to the cut and cover it with a sterile bandage.\\n\\n### Sources\\n[1] Provided context', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--966b6533-e0cd-45a5-9534-f2ffdb3e3cf7-0')]\n",
      "Token usage: [None]\n"
     ]
    }
   ],
   "source": [
    "def test_generate_response():\n",
    "    \"\"\"Test the generate_response function with sample data and check token counting.\"\"\"\n",
    "    # Create a mock state\n",
    "    test_state = {\n",
    "        \"question\": \"How do I treat a simple cut?\",\n",
    "        \"retrived_docs\": [\"Clean the wound with mild soap and water. Apply antibiotic ointment and cover with a sterile bandage.\"],\n",
    "        \"summary\": \"This is the first question in the conversation.\"\n",
    "    }\n",
    "    \n",
    "    # Call the function\n",
    "    result = generate_response(test_state)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"---TEST RESULTS---\")\n",
    "    print(f\"Generated answer: {result['answer']}\")\n",
    "    print(f\"Token usage: {result['token_usage']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run the test\n",
    "test_result = test_generate_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac151d-0125-4c67-ab1f-a141d044a306",
   "metadata": {},
   "source": [
    "# Web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf79aea5-d9ac-4864-87d1-3cf39d2d07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "tavily_search = TavilyClient(api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abbf95d8-639c-4c87-ae61-f32bb5a05971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state):\n",
    "    '''\n",
    "    Search the internet using, tavily\n",
    "\n",
    "    Args:\n",
    "        state(dict) : The current graph state.\n",
    "\n",
    "    Return:\n",
    "        Dict: New state with a key \"retrived_docs\"\n",
    "    \n",
    "    '''\n",
    "\n",
    "    print(\"---WEB_SEARCH---\")\n",
    "    question = state['question']\n",
    "    search_response = tavily_search.search(question) \n",
    "    if \"results\" not in search_response:\n",
    "        raise ValueError(\"Invalid response from Tavily API\")\n",
    "     \n",
    "    documents = [{\"url\": result['url'], \"content\": result['content']} for result in search_response['results']]\n",
    "\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "            for doc in documents\n",
    "        ]\n",
    "    )\n",
    "    return {\"retrived_docs\" : formatted_search_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f7565",
   "metadata": {},
   "source": [
    "# Route question\n",
    "\n",
    "Based on the question the Router decides whether to direct the question to retrieve context from vectorstore or perform a web search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af0db08b-e2dd-4afc-b8b0-61ee199a975c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='retrive'\n",
      "source='web_search'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "class RouteQuery(BaseModel):\n",
    "    source : Literal[\"retrive\", \"web_search\"] = Field(... , description=\"Given a user question route to web_search or to a retrive\")\n",
    "\n",
    "query_llm = model_for_query_route.with_structured_output(RouteQuery)\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", route_question_template),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "router = route_prompt | query_llm\n",
    "print(router.invoke({\"question\": \"Give me a  guidelines for minor scraps?\"}))\n",
    "print(router.invoke({\"question\": \"Who is the current president of Frane?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11280c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web_search or llm \n",
    "    Args:\n",
    "        state (dict): The current graph state.\n",
    "\n",
    "    Returns:\n",
    "        dict: New node to call \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---ROUTING---\")\n",
    "\n",
    "    question = state['question']\n",
    "\n",
    "    route = router.invoke({\"question\" : question})\n",
    "    \n",
    "    if route.source == \"retrive\":\n",
    "        print(\"ROUTE QUESTION TO RAG\")\n",
    "        return \"retrive\"\n",
    "        \n",
    "    elif route.source == \"web_search\":\n",
    "        print(\"ROUTE QUESTION TO WEB SEARCH\")\n",
    "        return \"web_search\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ba656-9d8e-497d-8371-c747c409b81e",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bb1ba5d-5889-4fb9-b814-c0014cb6f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state):\n",
    "    \"\"\"\n",
    "    Updates the conversation summary by incorporating the latest question and answer.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        dict: Updates the summary key with the extended or newly created summary\n",
    "    \"\"\"\n",
    "    print(\"---SUMMARIZE_CONVERSATION---\")\n",
    "    \n",
    "   \n",
    "    question = state.get(\"question\", \"\")\n",
    "    answer = state.get(\"answer\", \"\")\n",
    "    token_count = state.get(\"token_usage\", [])\n",
    "    \n",
    "    history = state.get(\"history\", [])\n",
    "    if not isinstance(history, list):\n",
    "        history = []  \n",
    "\n",
    "    new_exchange = {\"question\": question, \"answer\": answer}\n",
    "    history.append(new_exchange)\n",
    "\n",
    "    history_text = \"\\n\".join([f\"Q: {ex['question']}\\nA: {ex['answer']}\" for ex in history])\n",
    "    summary_prompt = f\"Current conversation summary:\\n{history_text}\\n\\nExtend the summary with the new exchange:\\nQ: {question}\\nA: {answer}\"\n",
    "    \n",
    "    response = model_for_query_route.invoke(summary_prompt)\n",
    "    tokens = response.usage_metadata\n",
    "    token_count.append(tokens)\n",
    "    state[\"token_usage\"] = token_count\n",
    "    \n",
    "    return {\n",
    "        \"history\": history,\n",
    "        \"summary\": response \n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b03b3c-b220-4196-9e05-7026bb88da9e",
   "metadata": {},
   "source": [
    "# Corrective Retrieval Augmented Generation\n",
    "https://arxiv.org/pdf/2401.15884\n",
    "\n",
    "Corrective-RAG (CRAG) is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents.\n",
    "\n",
    "With this feature, the system works more intelligently - it doesn't generate answers based on irrelevant or incomplete data, but instead automatically looks for better information on its own when necessary.\n",
    "This improves the accuracy and quality of answers.\n",
    "\n",
    "### Document grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7d07cde-a083-4338-af49-04c73d8baa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    score : bool = Field(... , description=\"Documents are relevant to the question, 'True' or 'False'\")\n",
    "\n",
    "grader_llm = model_for_query_route.with_structured_output(GradeDocuments)\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\" , grade_documents_template),\n",
    "    (\"human\", \"DOCUMENTS: \\n\\n {documents} \\n\\n QUESTION: {question}\")\n",
    "])\n",
    "\n",
    "documents_grader = grade_prompt | grader_llm\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "    print(\"---GRADE RETRIVED DOCUMENTS---\")\n",
    "    question = state.get(\"question\")\n",
    "    retrived_docuemnts = state.get(\"retrived_docs\")\n",
    "\n",
    "    filtere_documents = []\n",
    "\n",
    "    for doc in retrived_docuemnts:\n",
    "\n",
    "        score = documents_grader.invoke({\"documents\" : doc , \"question\" : question})\n",
    "\n",
    "        if score.score == True:\n",
    "            filtere_documents.append(doc)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    score = documents_grader.invoke({\"documents\" : retrived_docuemnts , \"question\" : question})\n",
    "    print(score.score)\n",
    "    return {\"retrived_docs\" : filtere_documents,\"are_documents_relevant\" : score.score}\n",
    "    \n",
    "\n",
    "def route_graded(state):\n",
    "    \"\"\" Route the research based on the documents relevance \"\"\"\n",
    "    \n",
    "    score = state.get(\"are_documents_relevant\")\n",
    "\n",
    "    if score == True:\n",
    "        print(\"ROUTE TO GENERATE\")\n",
    "        return \"generate_response\"\n",
    "    else:\n",
    "        print(\"ROUTE TO WEB SEARCH\")\n",
    "        return \"web_search\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a58502-7d02-43ae-876f-1f239470256a",
   "metadata": {},
   "source": [
    "### Hallucination checker, Answer grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962acd17-3de2-40e6-8a41-a57f85bdc100",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckHallucination(BaseModel):\n",
    "    score : bool = Field(... , description=\"Answer are relevant to the retrived documents, True or False\")\n",
    "    \n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    grade: bool = Field(\n",
    "        description=\"Answer addresses the question, True or False\"\n",
    "    )\n",
    "hallucination_checker_llm = model_for_query_route.with_structured_output(CheckHallucination)\n",
    "structured_llm_grader = model_for_query_route.with_structured_output(GradeAnswer)\n",
    "\n",
    "\n",
    "\n",
    "check_hallucination_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\" , check_hallucination_template),\n",
    "    (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {answer}\"),\n",
    "])\n",
    "\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", answer_question_template),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "hallucination_checker = check_hallucination_prompt | hallucination_checker_llm\n",
    "\n",
    "def check_hallucination_grade_answer(state):\n",
    "    \"\"\"\n",
    "    Check hallucination and grade the answer. If the process fails twice, skip further checks and return the current answer.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state.\n",
    "    \n",
    "    Returns:\n",
    "        str: The next node to call.\n",
    "    \"\"\"\n",
    "    print(\"---CHECK HALLUCINATION AND GRADE ANSWER---\")\n",
    "\n",
    "    question = state.get(\"question\")\n",
    "    documents = state.get(\"retrived_docs\")\n",
    "    answer = state.get(\"answer\") \n",
    "    score = hallucination_checker.invoke({\"documents\" : documents , \"answer\" : answer})\n",
    "\n",
    "    # Initialize or increment the retry counter\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "    state[\"retry_count\"] = retry_count + 1\n",
    "\n",
    "    # If this is the third attempt, skip checks and return the current answer\n",
    "    if retry_count >= 2:\n",
    "        print(\"---MAX RETRIES REACHED: RETURNING CURRENT ANSWER---\")\n",
    "        return \"summarize\"\n",
    "    # Check hallucination\n",
    "    \n",
    "    print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "    grade = answer_grader.invoke({\"question\": question, \"generation\": answer})\n",
    "    grade = grade.grade\n",
    "\n",
    "\n",
    "    if grade == True:\n",
    "        print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "        return \"summarize\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "        return \"not useful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b27d1fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING HALLUCINATION CHECKER ===\n",
      "\n",
      "Test 1: Factually aligned generation\n",
      "Expected: True, Got: False\n",
      "PASS: False\n",
      "\n",
      "Test 2: Contradictory generation\n",
      "Expected: False, Got: False\n",
      "PASS: True\n",
      "\n",
      "Test 3: Generation with added information not in documents\n",
      "Expected: False, Got: False\n",
      "PASS: True\n",
      "\n",
      "=== TESTING ANSWER GRADER ===\n",
      "\n",
      "Test 1: Relevant and complete answer\n",
      "Expected: True, Got: False\n",
      "PASS: False\n",
      "\n",
      "Test 2: Off-topic answer\n",
      "Expected: False, Got: False\n",
      "PASS: True\n",
      "\n",
      "Test 3: Incomplete answer for a serious condition\n",
      "Expected: False, Got: False\n",
      "PASS: True\n",
      "\n",
      "=== TESTING CHECK_HALLUCINATION_GRADE_ANSWER FUNCTION ===\n",
      "---CHECK HALLUCINATION AND GRADE ANSWER---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "Test case 1 - First attempt with good answer\n",
      "Result: not useful\n",
      "Retry count: 1\n",
      "---CHECK HALLUCINATION AND GRADE ANSWER---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\n",
      "\n",
      "Test case 2 - First attempt with irrelevant answer\n",
      "Result: not useful\n",
      "Retry count: 1\n",
      "---CHECK HALLUCINATION AND GRADE ANSWER---\n",
      "---MAX RETRIES REACHED: RETURNING CURRENT ANSWER---\n",
      "\n",
      "Test case 3 - Max retries reached\n",
      "Result: summarize\n",
      "Retry count: 3\n"
     ]
    }
   ],
   "source": [
    "def test_hallucination_and_grade_answer():\n",
    "    \"\"\"\n",
    "    Test the check_hallucination_grade_answer function, hallucination checker, and answer grader\n",
    "    with various test cases.\n",
    "    \n",
    "    This tests:\n",
    "    1. Hallucination detection (facts vs generation)\n",
    "    2. Answer grading (question vs generation)\n",
    "    3. Proper retry handling\n",
    "    4. Edge cases\n",
    "    \"\"\"\n",
    "    # Test Hallucination Checker\n",
    "    print(\"=== TESTING HALLUCINATION CHECKER ===\")\n",
    "    hallucination_test_cases = [\n",
    "        {\n",
    "            \"documents\": \"Honey bee stings should be removed by scraping with a flat edge.\",\n",
    "            \"answer\": \"Remove a honey bee sting by scraping it off with a credit card or similar flat object.\",\n",
    "            \"expected\": True,\n",
    "            \"description\": \"Factually aligned generation\"\n",
    "        },\n",
    "        {\n",
    "            \"documents\": \"Honey bee stings should be removed by scraping with a flat edge.\",\n",
    "            \"answer\": \"You should always use tweezers to remove bee stings by pulling them out.\",\n",
    "            \"expected\": False,\n",
    "            \"description\": \"Contradictory generation\"\n",
    "        },\n",
    "        {\n",
    "            \"documents\": \"Minor cuts should be cleaned with soap and water.\",\n",
    "            \"answer\": \"Clean cuts with mild soap and water, then apply antibiotic ointment.\",\n",
    "            \"expected\": False,\n",
    "            \"description\": \"Generation with added information not in documents\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, test in enumerate(hallucination_test_cases):\n",
    "        print(f\"\\nTest {i+1}: {test['description']}\")\n",
    "        result = hallucination_checker.invoke({\n",
    "            \"documents\": test[\"documents\"],\n",
    "            \"answer\": test[\"answer\"]\n",
    "        })\n",
    "        print(f\"Expected: {test['expected']}, Got: {result.score}\")\n",
    "        print(f\"PASS: {result.score == test['expected']}\")\n",
    "    \n",
    "    # Test Answer Grader\n",
    "    print(\"\\n=== TESTING ANSWER GRADER ===\")\n",
    "    grader_test_cases = [\n",
    "        {\n",
    "            \"question\": \"How do I treat a bee sting?\",\n",
    "            \"generation\": \"To treat a bee sting, remove the stinger by scraping it off, wash with soap and water, apply ice to reduce swelling, and take antihistamines if needed.\",\n",
    "            \"expected\": True,\n",
    "            \"description\": \"Relevant and complete answer\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How do I treat a bee sting?\",\n",
    "            \"generation\": \"Bees are flying insects closely related to wasps and ants, and are known for their role in pollination.\",\n",
    "            \"expected\": False,\n",
    "            \"description\": \"Off-topic answer\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What should I do for a deep cut that won't stop bleeding?\",\n",
    "            \"generation\": \"For any cut, clean it with soap and water.\",\n",
    "            \"expected\": False,\n",
    "            \"description\": \"Incomplete answer for a serious condition\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for i, test in enumerate(grader_test_cases):\n",
    "        print(f\"\\nTest {i+1}: {test['description']}\")\n",
    "        result = answer_grader.invoke({\n",
    "            \"question\": test[\"question\"],\n",
    "            \"generation\": test[\"generation\"]\n",
    "        })\n",
    "        print(f\"Expected: {test['expected']}, Got: {result.grade}\")\n",
    "        print(f\"PASS: {result.grade == test['expected']}\")\n",
    "    \n",
    "    # Test the check_hallucination_grade_answer function with mock state\n",
    "    print(\"\\n=== TESTING CHECK_HALLUCINATION_GRADE_ANSWER FUNCTION ===\")\n",
    "    \n",
    "    # Test Case 1: First attempt - good answer\n",
    "    test_state_1 = {\n",
    "        \"question\": \"How do I treat a bee sting?\",\n",
    "        \"retrived_docs\": \"Remove the stinger by scraping it with a flat edge. Clean with soap and water. Apply cold compress.\",\n",
    "        \"answer\": \"To treat a bee sting, first remove the stinger by scraping it with a credit card or similar flat edge. Then wash the area with soap and water, and apply a cold compress to reduce swelling.\"\n",
    "    }\n",
    "    \n",
    "    result_1 = check_hallucination_grade_answer(test_state_1)\n",
    "    print(f\"Test case 1 - First attempt with good answer\")\n",
    "    print(f\"Result: {result_1}\")\n",
    "    print(f\"Retry count: {test_state_1.get('retry_count', 0)}\")\n",
    "    \n",
    "    # Test Case 2: First attempt - hallucination or off-topic\n",
    "    test_state_2 = {\n",
    "        \"question\": \"How do I treat a bee sting?\",\n",
    "        \"retrived_docs\": \"Remove the stinger by scraping it with a flat edge. Clean with soap and water. Apply cold compress.\",\n",
    "        \"answer\": \"Bees are flying insects known for their role in pollination and honey production.\"\n",
    "    }\n",
    "    \n",
    "    result_2 = check_hallucination_grade_answer(test_state_2)\n",
    "    print(f\"\\nTest case 2 - First attempt with irrelevant answer\")\n",
    "    print(f\"Result: {result_2}\")\n",
    "    print(f\"Retry count: {test_state_2.get('retry_count', 0)}\")\n",
    "    \n",
    "    # Test Case 3: Max retries reached\n",
    "    test_state_3 = {\n",
    "        \"question\": \"How do I treat a bee sting?\",\n",
    "        \"retrived_docs\": \"Remove the stinger by scraping it with a flat edge. Clean with soap and water. Apply cold compress.\",\n",
    "        \"answer\": \"Bees are flying insects known for their role in pollination and honey production.\",\n",
    "        \"retry_count\": 2  # Already failed twice\n",
    "    }\n",
    "    \n",
    "    result_3 = check_hallucination_grade_answer(test_state_3)\n",
    "    print(f\"\\nTest case 3 - Max retries reached\")\n",
    "    print(f\"Result: {result_3}\")\n",
    "    print(f\"Retry count: {test_state_3.get('retry_count', 0)}\")\n",
    "    \n",
    "    return \"All tests completed\"\n",
    "\n",
    "# Execute the tests\n",
    "if __name__ == \"__main__\":\n",
    "    test_hallucination_and_grade_answer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34aaed25-f134-4884-81ed-4f2a49c323c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=True\n",
      "score=False\n"
     ]
    }
   ],
   "source": [
    "print(hallucination_checker.invoke({\n",
    "    \"documents\": \"The capital of France is Paris.\",\n",
    "    \"answer\": \"Paris is the capital of France.\"\n",
    "}))\n",
    "\n",
    "print(hallucination_checker.invoke({\n",
    "    \"documents\": \"The capital of France is Paris.\",\n",
    "    \"answer\": \"The capital of France is Lyon.\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b71bfe7f-2d0d-4ce4-a6e1-56d31e5c53e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grade=True\n",
      "grade=False\n"
     ]
    }
   ],
   "source": [
    "print(answer_grader.invoke({\n",
    "    \"question\": \"Who discovered penicillin?\",\n",
    "    \"generation\": \"Alexander Fleming discovered penicillin in 1928.\"\n",
    "}))\n",
    "\n",
    "print(answer_grader.invoke({\n",
    "    \"question\": \"What is the boiling point of water?\",\n",
    "    \"generation\": \"Water is an important molecule for life.\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c9a5a",
   "metadata": {},
   "source": [
    "# Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "321b599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode ,tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict , Annotated , List , Dict\n",
    "from langchain_core.messages import AIMessage, AnyMessage, HumanMessage, SystemMessage, RemoveMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "import operator\n",
    "\n",
    "config = {\"configurable\" : {\"thread_id\": \"1\"}}\n",
    "memory = MemorySaver()\n",
    "\n",
    "class MedicalAssistantState(TypedDict):\n",
    "    image: str\n",
    "    image_metadata: dict\n",
    "    question: str\n",
    "    answer: str\n",
    "    retrived_docs : List[str] \n",
    "    history: List[Dict[str, str]]  \n",
    "    summary: str\n",
    "    are_documents_relevant : bool\n",
    "    retry_count : int\n",
    "    token_usage : List[Dict[str, int]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38585fb-32d2-4ded-ab1e-266ec96abe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder_2 = StateGraph(MedicalAssistantState)\n",
    "builder_2.add_node(\"analyze_image\", analyze_image_node,)\n",
    "builder_2.add_node(\"generate_response\", generate_response)\n",
    "builder_2.add_node(\"retrive\" , retrive)\n",
    "builder_2.add_node(\"web_search\" , web_search)\n",
    "builder_2.add_node(\"summarize\" , summarize_conversation)\n",
    "builder_2.add_node(\"grade_documents\" , grade_documents)\n",
    "\n",
    "builder_2.add_edge(START , \"analyze_image\")\n",
    "builder_2.add_conditional_edges(\"analyze_image\" , route_question , {\"web_search\" : \"web_search\" , \"retrive\" :\"retrive\"})\n",
    "builder_2.add_edge(\"retrive\" , \"grade_documents\")\n",
    "builder_2.add_conditional_edges(\"grade_documents\" , route_graded , {\"generate_response\" : \"generate_response\" , \"web_search\" : \"web_search\"})\n",
    "builder_2.add_edge(\"web_search\" , \"generate_response\")\n",
    "builder_2.add_conditional_edges(\"generate_response\" , check_hallucination_grade_answer , {\"summarize\" : \"summarize\"  , \"not useful\" : \"generate_response\"})\n",
    "builder_2.add_edge(\"summarize\", END)\n",
    "\n",
    "test_graph= builder_2.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7501cf3-6d36-40e0-92e2-fb34cb2ac17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Image(test_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60d5baf3-3ad0-4410-80e3-da315ac19373",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MedicalAssistantState)\n",
    "\n",
    "builder.add_node(\"analyze_image\", analyze_image_node,)\n",
    "builder.add_node(\"generate_response\", generate_response)\n",
    "builder.add_node(\"retrive\" , retrive)\n",
    "builder.add_node(\"web_search\" , web_search)\n",
    "\n",
    "\n",
    "builder.add_edge(START, \"analyze_image\")\n",
    "builder.add_edge(\"analyze_image\", \"web_search\")\n",
    "builder.add_edge(\"analyze_image\", \"retrive\")\n",
    "builder.add_edge(\"web_search\", \"generate_response\")\n",
    "builder.add_edge(\"retrive\", \"generate_response\")\n",
    "builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "medical_assistant_parallel  = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ed0cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---IMAGE ANALYSIS---\n",
      "No image provided to input\n",
      "---ROUTING---\n",
      "ROUTE QUESTION TO WEB SEARCH\n",
      "---WEB_SEARCH---\n",
      "---GENERATION OF RESPONSE---\n",
      "---CHECK HALLUCINATION AND GRADE ANSWER---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---SUMMARIZE_CONVERSATION---\n",
      "{'question': 'What should I do when something bites my hand?', 'answer': [AIMessage(content=\"If a human bite breaks your skin, it's important to seek medical care from a doctor, ideally within 24 hours, due to the high risk of infection. A health professional may offer antibiotics, especially if the bite involves high-risk areas like the hands, feet, face, genitals, skin over joints, or areas with poor circulation, or if you have a medical condition that increases your risk of wound infection. If the wound doesn’t stop bleeding or the bite has removed significant tissue, seek help at an emergency room. Cleaning and bandaging the wound are frequent treatments for human bites.\\n\\n### Sources\\n[1] https://www.healthline.com/health/human-bites  \\n[2] https://www.wikihow.com/Treat-a-Human-Bite  \\n[3] https://patient.info/treatment-medication/human-bites\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--3d7b8bfd-1c30-4e0f-8d24-cbcee95afef2-0')], 'retrived_docs': '<Document href=\"https://www.healthline.com/health/human-bites\"/>\\nHuman Bites: Symptoms, Infection, Treatments, and Recovery Human Bites What are human bites? If you have a bite that has become infected, you may need medication or surgery. According to the American Academy of Orthopaedic Surgeons, human bite wounds cause about one-third of all hand infections. Who is at risk for human bites? Treating human bites: First aid and medical assistance Cleaning and bandaging the wound are frequent treatments for human bites. How can I prevent human bites? Recovering from a human bite depends on its severity and whether the wound becomes infected. Health & Well-being Human bites: First aid. Medically reviewed by Stacy Sampson, D.O. Skin abrasions can often be treated at home, but third-degree abrasions require medical treatment.\\n</Document>\\n\\n---\\n\\n<Document href=\"https://www.wikihow.com/Treat-a-Human-Bite\"/>\\nIf a human bite breaks your skin, you’ll need to see a doctor and get medical care in addition to administering first aid.[8] X Trustworthy Source Mayo Clinic Educational website from one of the world\\'s leading hospitals Go to source It’s important to see your doctor if a human bite breaks your skin, as it can very easily become infected.[27] X Trustworthy Source Mayo Clinic Educational website from one of the world\\'s leading hospitals Go to source You should seek treatment for a broken skin wound within 24 hours.[28] X Research source If your wound doesn’t stop bleeding or the bite has removed significant tissue, seek help at an emergency room.[29] X Trustworthy Source Mayo Clinic Educational website from one of the world\\'s leading hospitals Go to source\\n</Document>\\n\\n---\\n\\n<Document href=\"https://patient.info/treatment-medication/human-bites\"/>\\nFollowing a human bite, it is usually worth seeing a doctor or health professional for advice. What treatment might I need from a health professional for a human bite? What treatment might I need from a health professional for a human bite? If the bite has broken the skin but not drawn blood, antibiotics will be offered if it involves a high-risk area such as the hands, feet, face, genitals, skin over joints or an area of poor circulation, or if you are at higher risk of a serious wound infection because of a medical condition such as: The most common complication following a bite is infection of the wound.\\n</Document>\\n\\n---\\n\\n<Document href=\"https://www.familytoday.com/self-care/if-you-were-stung-by-something-and-you-dont-know-what-it-was-we-can-tell-you-how-to-identify-the-most-common-bites-5-of-them-can-be-extremely-dangerous/\"/>\\nBug bites often cause pain, but the actual bug leaves before the pain starts so the bites are hard to identify. In many cases, not knowing this information can complicate things, and sometimes cause serious problems. Here are some bug bites you should be aware of and their symptoms: Dangerous bites 1. Bed bugs\\n</Document>\\n\\n---\\n\\n<Document href=\"https://www.healthline.com/health/bug-bites\"/>\\nBites and Stings: Pictures, Causes, Symptoms, and Treatment #### Bites and Stings Identifying Bug Bites and Stings, and How to Treat Them The initial contact of a bite or sting from a bug may be painful. Pictures of bites and stings Types of biting and stinging insects and arachnids Who is at risk of bites and stings? Anyone can be bitten or stung by an insect or arachnid, and bites and stings are very common. What are the symptoms of a bad reaction to bites and stings? Treating bites and stings To treat a bite or sting: Bites and stings that cause severe reactions can be fatal if they aren’t treated immediately. Bites and stings. https://www.aad.org/public/everyday-care/injured-skin/bites/treat-bee-sting Insect bites and stings.\\n</Document>', 'history': [{'question': 'What should I do when something bites my hand?', 'answer': [AIMessage(content=\"If a human bite breaks your skin, it's important to seek medical care from a doctor, ideally within 24 hours, due to the high risk of infection. A health professional may offer antibiotics, especially if the bite involves high-risk areas like the hands, feet, face, genitals, skin over joints, or areas with poor circulation, or if you have a medical condition that increases your risk of wound infection. If the wound doesn’t stop bleeding or the bite has removed significant tissue, seek help at an emergency room. Cleaning and bandaging the wound are frequent treatments for human bites.\\n\\n### Sources\\n[1] https://www.healthline.com/health/human-bites  \\n[2] https://www.wikihow.com/Treat-a-Human-Bite  \\n[3] https://patient.info/treatment-medication/human-bites\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--3d7b8bfd-1c30-4e0f-8d24-cbcee95afef2-0')]}], 'summary': AIMessage(content='Unfortunately, there is no new exchange to add to the summary as the response provided does not contain any additional information or a new question. The same answer is repeated, with no new context or details.\\n\\nIf you would like, I can help you create a new summary based on the original conversation, or we can continue from here and add any new exchanges that are added to the conversation. Let me know how I can assist!', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-05-18T17:20:47.721673Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1411083200, 'load_duration': 21063000, 'prompt_eval_count': 596, 'prompt_eval_duration': 142000000, 'eval_count': 86, 'eval_duration': 1246000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run--2d6b788f-0729-41a7-aa28-a80a9837ba71-0', usage_metadata={'input_tokens': 596, 'output_tokens': 86, 'total_tokens': 682}), 'token_usage': [None, {'input_tokens': 596, 'output_tokens': 86, 'total_tokens': 682}]}\n"
     ]
    }
   ],
   "source": [
    "img_path = r\"E:\\Deep_Learning\\Skin diseases\\data_multiclass\\Wound\\Cut\\cut (15).jpg\"\n",
    "\n",
    "response = test_graph.invoke({\"question\" : \"What should I do when something bites my hand?\"} , config=config)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ece1559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"If a human bite breaks your skin, it's important to seek medical care from a doctor, ideally within 24 hours, due to the high risk of infection. A health professional may offer antibiotics, especially if the bite involves high-risk areas like the hands, feet, face, genitals, skin over joints, or areas with poor circulation, or if you have a medical condition that increases your risk of wound infection. If the wound doesn’t stop bleeding or the bite has removed significant tissue, seek help at an emergency room. Cleaning and bandaging the wound are frequent treatments for human bites.\\n\\n### Sources\\n[1] https://www.healthline.com/health/human-bites  \\n[2] https://www.wikihow.com/Treat-a-Human-Bite  \\n[3] https://patient.info/treatment-medication/human-bites\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--3d7b8bfd-1c30-4e0f-8d24-cbcee95afef2-0'\n"
     ]
    }
   ],
   "source": [
    "for m in response['answer']:\n",
    "    print(m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d982b85-8d65-4c57-a588-79955f70ea40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---IMAGE ANALYSIS---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "---ROUTING---\n",
      "ROUTE QUESTION TO RAG\n",
      "---RETRIVE---\n",
      "Retrieval query: This question relates to a medical image classified as: Wound with probability 0.9996616840362549\n",
      "---GRADE RETRIVED DOCUMENTS---\n",
      "False\n",
      "ROUTE TO WEB SEARCH\n",
      "---WEB_SEARCH---\n",
      "---GENERATION OF RESPONSE---\n",
      "---CHECK HALLUCINATION AND GRADE ANSWER---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---SUMMARIZE_CONVERSATION---\n"
     ]
    }
   ],
   "source": [
    "response_2 = test_graph.invoke({\"question\" : \"I've cut through what to do?\" , \"image\" : img_path} , config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8f72f5a-4aab-4e21-8d77-f11f23c8cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='If you cut yourself, the first thing you should do is apply pressure with a clean bandage or cloth, and keep that part of your body elevated above the heart, if possible. You may be tempted to lift the towel or gauze every few minutes to check on the cut, but avoid the urge, as this can reopen the cut and cause more bleeding. Cover the area with a clean, sterile bandage, change the bandage daily to keep the cut clean and dry, and wash your hands again. If blood spurts out of your cut, you have an abdominal or chest wound, or bleeding is so severe that it pools on the ground or soaks through your clothes, then call 9-1-1. If the cut is painful, you can take over-the-counter pain medication to reduce discomfort. Go to Urgent Care if the cut is gaping open, deep or jagged around the edges.\\n\\n### Sources\\n[1] https://www.self.com/story/stop-bleeding-cut  \\n[2] https://www.consumerreports.org/health/first-aid/how-to-treat-a-cut-a1032626330/  \\n[3] https://healthywithpardee.com/how-to-treat-a-cut-at-home/  \\n[4] https://www.piedmont.org/living-real-change/first-aid-101-how-to-treat-a-cut  \\n[5] https://www.prevention.com/health/a25999058/how-to-stop-a-cut-from-bleeding/' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--6a24f95e-ed27-4d0c-9158-eae6e7247c5a-0'\n"
     ]
    }
   ],
   "source": [
    "for m in response_2['answer']:\n",
    "    print(m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42ee6964-20b9-44bc-8429-57142c9167e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unfortunately, there is no new exchange to add to the summary as the response provided does not contain any additional information or a new question. The same answer is repeated, with no new context or details.\\n\\nIf you would like, I can help you create a new summary based on the original conversation, or we can continue from here and add any new exchanges that are added to the conversation. Let me know how I can assist!'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['summary'].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84b28687-6d9a-4deb-b184-01b0ca21a084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is the extended conversation summary:\\n\\nQ: I've cut through what to do?\\nA: [AIMessage(content='If you cut yourself, the first thing you should do is apply pressure with a clean bandage or cloth, and keep that part of your body elevated above the heart, if possible. You may be tempted to lift the towel or gauze every few minutes to check on the cut, but avoid the urge, as this can reopen the cut and cause more bleeding. Cover the area with a clean, sterile bandage, change the bandage daily to keep the cut clean and dry, and wash your hands again. If blood spurts out of your cut, you have an abdominal or chest wound, or bleeding is so severe that it pools on the ground or soaks through your clothes, then call 9-1-1. If the cut is painful, you can take over-the-counter pain medication to reduce discomfort. Go to Urgent Care if the cut is gaping open, deep or jagged around the edges.\\\\n\\\\n### Sources\\\\n[1] https://www.self.com/story/stop-bleeding-cut  \\\\n[2] https://www.consumerreports.org/health/first-aid/how-to-treat-a-cut-a1032626330/  \\\\n[3] https://healthywithpardee.com/how-to-treat-a-cut-at-home/  \\\\n[4] https://www.piedmont.org/living-real-change/first-aid-101-how-to-treat-a-cut  \\\\n[5] https://www.prevention.com/health/a25999058/how-to-stop-a-cut-from-bleeding/', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--6a24f95e-ed27-4d0c-9158-eae6e7247c5a-0')]\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2['summary'].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "873d2547-cf40-499a-9b93-6ee4174da26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': \"I've cut through what to do?\",\n",
       "  'answer': [AIMessage(content='If you cut yourself, the first thing you should do is apply pressure with a clean bandage or cloth, and keep that part of your body elevated above the heart, if possible. You may be tempted to lift the towel or gauze every few minutes to check on the cut, but avoid the urge, as this can reopen the cut and cause more bleeding. Cover the area with a clean, sterile bandage, change the bandage daily to keep the cut clean and dry, and wash your hands again. If blood spurts out of your cut, you have an abdominal or chest wound, or bleeding is so severe that it pools on the ground or soaks through your clothes, then call 9-1-1. If the cut is painful, you can take over-the-counter pain medication to reduce discomfort. Go to Urgent Care if the cut is gaping open, deep or jagged around the edges.\\n\\n### Sources\\n[1] https://www.self.com/story/stop-bleeding-cut  \\n[2] https://www.consumerreports.org/health/first-aid/how-to-treat-a-cut-a1032626330/  \\n[3] https://healthywithpardee.com/how-to-treat-a-cut-at-home/  \\n[4] https://www.piedmont.org/living-real-change/first-aid-101-how-to-treat-a-cut  \\n[5] https://www.prevention.com/health/a25999058/how-to-stop-a-cut-from-bleeding/', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--6a24f95e-ed27-4d0c-9158-eae6e7247c5a-0')]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9222841e-ad8d-4007-946a-19fd0ea0d948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, {'input_tokens': 866, 'output_tokens': 422, 'total_tokens': 1288}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2['token_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "691690db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, {'input_tokens': 596, 'output_tokens': 86, 'total_tokens': 682}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['token_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93089438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
